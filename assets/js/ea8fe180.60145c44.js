"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[841],{5591:(e,n,t)=>{t.d(n,{xA:()=>u,yg:()=>y});var a=t(8527);function i(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function r(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function o(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?r(Object(t),!0).forEach((function(n){i(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function l(e,n){if(null==e)return{};var t,a,i=function(e,n){if(null==e)return{};var t,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)t=r[a],n.indexOf(t)>=0||(i[t]=e[t]);return i}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)t=r[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(i[t]=e[t])}return i}var s=a.createContext({}),p=function(e){var n=a.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):o(o({},n),e)),t},u=function(e){var n=p(e.components);return a.createElement(s.Provider,{value:n},e.children)},d="mdxType",g={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},c=a.forwardRef((function(e,n){var t=e.components,i=e.mdxType,r=e.originalType,s=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),d=p(t),c=i,y=d["".concat(s,".").concat(c)]||d[c]||g[c]||r;return t?a.createElement(y,o(o({ref:n},u),{},{components:t})):a.createElement(y,o({ref:n},u))}));function y(e,n){var t=arguments,i=n&&n.mdxType;if("string"==typeof e||i){var r=t.length,o=new Array(r);o[0]=c;var l={};for(var s in n)hasOwnProperty.call(n,s)&&(l[s]=n[s]);l.originalType=e,l[d]="string"==typeof e?e:i,o[1]=l;for(var p=2;p<r;p++)o[p]=t[p];return a.createElement.apply(null,o)}return a.createElement.apply(null,t)}c.displayName="MDXCreateElement"},3668:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>o,default:()=>g,frontMatter:()=>r,metadata:()=>l,toc:()=>p});var a=t(4465),i=(t(8527),t(5591));const r={id:"serve",sidebar_label:"serve"},o="Rivet CLI - serve Command",l={unversionedId:"cli/serve",id:"cli/serve",title:"Rivet CLI - serve Command",description:"Serve a Rivet project using a local server.",source:"@site/docs/cli/serve.md",sourceDirName:"cli",slug:"/cli/serve",permalink:"/docs/cli/serve",draft:!1,editUrl:"https://github.com/ironclad/rivet/tree/main/packages/docs/docs/cli/serve.md",tags:[],version:"current",frontMatter:{id:"serve",sidebar_label:"serve"},sidebar:"cli",previous:{title:"run",permalink:"/docs/cli/run"},next:{title:"Docker",permalink:"/docs/cli/docker"}},s={},p=[{value:"Quick Start",id:"quick-start",level:2},{value:"Description",id:"description",level:2},{value:"Usage",id:"usage",level:2},{value:"Inputs",id:"inputs",level:2},{value:"Outputs",id:"outputs",level:2},{value:"Endpoints",id:"endpoints",level:2},{value:"<code>POST /</code>",id:"post-",level:3},{value:"<code>POST/:graphId</code>",id:"postgraphid",level:3},{value:"Options",id:"options",level:2},{value:"Server Configuration",id:"server-configuration",level:3},{value:"Graph Selection",id:"graph-selection",level:3},{value:"OpenAI Configuration",id:"openai-configuration",level:3},{value:"Monitoring",id:"monitoring",level:3},{value:"Examples",id:"examples",level:2},{value:"Running a Simple Graph",id:"running-a-simple-graph",level:3},{value:"Security Considerations",id:"security-considerations",level:2},{value:"Streaming Mode",id:"streaming-mode",level:2},{value:"Rivet Events Streaming Mode",id:"rivet-events-streaming-mode",level:3},{value:"Single-Node Streaming Mode",id:"single-node-streaming-mode",level:4},{value:"Text Streaming Mode",id:"text-streaming-mode",level:3}],u={toc:p},d="wrapper";function g(e){let{components:n,...t}=e;return(0,i.yg)(d,(0,a.A)({},u,t,{components:n,mdxType:"MDXLayout"}),(0,i.yg)("h1",{id:"rivet-cli---serve-command"},"Rivet CLI - ",(0,i.yg)("inlineCode",{parentName:"h1"},"serve")," Command"),(0,i.yg)("p",null,"Serve a Rivet project using a local server."),(0,i.yg)("h2",{id:"quick-start"},"Quick Start"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-bash"},"# Start server with default settings\nnpx @ironclad/rivet-cli serve\n\n# Start server on custom port\nnpx @ironclad/rivet-cli serve --port 8080\n\n# Start server in development mode\nnpx @ironclad/rivet-cli serve --dev\n")),(0,i.yg)("h2",{id:"description"},"Description"),(0,i.yg)("p",null,"The ",(0,i.yg)("inlineCode",{parentName:"p"},"serve")," command starts a local HTTP server that hosts your Rivet project, allowing you to execute graphs via HTTP requests. This is particularly useful for:"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},"Testing graphs in a production-like environment"),(0,i.yg)("li",{parentName:"ul"},"Integrating Rivet graphs into other applications"),(0,i.yg)("li",{parentName:"ul"},"Running graphs from scripts or automated tools"),(0,i.yg)("li",{parentName:"ul"},"Development and debugging of graph implementations")),(0,i.yg)("h2",{id:"usage"},"Usage"),(0,i.yg)("p",null,"The basic usage will serve the project file in the current directory, using the default port of 3000:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-bash"},"npx @ironclad/rivet-cli serve\n")),(0,i.yg)("p",null,"You can also specify a different project file or port:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-bash"},"npx @ironclad/rivet-cli serve my-project.rivet-project --port 8080\n")),(0,i.yg)("p",null,"Once the server is running, you can make POST requests to the server to run graphs."),(0,i.yg)("h2",{id:"inputs"},"Inputs"),(0,i.yg)("p",null,"Inputs to graphs are provided via the request body of the HTTP request. The request body should be a JSON object with the input values."),(0,i.yg)("p",null,"Input values should be provided as ",(0,i.yg)("a",{parentName:"p",href:"/docs/user-guide/data-types"},"Data Values"),", except for simple types like strings, numbers, and booleans."),(0,i.yg)("p",null,"For example, for a graph with two inputs, ",(0,i.yg)("inlineCode",{parentName:"p"},"input1")," (string) and ",(0,i.yg)("inlineCode",{parentName:"p"},"input2")," (object),\nthe request body should look like this:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "input1": "Hello, World!",\n  "input2": {\n    "type": "object",\n    "value": {\n      "key1": "value1",\n      "key2": 42\n    }\n  }\n}\n')),(0,i.yg)("h2",{id:"outputs"},"Outputs"),(0,i.yg)("p",null,"The server will respond with a JSON object that contains the output values of the graph. Each Graph Output node in the graph will correspond to a key in the output JSON object."),(0,i.yg)("p",null,"The value of each property will be a ",(0,i.yg)("a",{parentName:"p",href:"/docs/user-guide/data-types"},"Data Value")," object, with a ",(0,i.yg)("inlineCode",{parentName:"p"},"type")," property and a ",(0,i.yg)("inlineCode",{parentName:"p"},"value")," property."),(0,i.yg)("p",null,"For example, if a graph has two Graph Output Nodes, ",(0,i.yg)("inlineCode",{parentName:"p"},"output1")," (a string) and ",(0,i.yg)("inlineCode",{parentName:"p"},"output2")," (a number), the output JSON object will look like this:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "output1": {\n    "type": "string",\n    "value": "Hello, World!"\n  },\n  "output2": {\n    "type": "number",\n    "value": 42\n  }\n}\n')),(0,i.yg)("h2",{id:"endpoints"},"Endpoints"),(0,i.yg)("h3",{id:"post-"},(0,i.yg)("inlineCode",{parentName:"h3"},"POST /")),(0,i.yg)("p",null,"Run the main graph in the project file. The request body should contain the input values as described above."),(0,i.yg)("p",null,"Outputs a JSON object with the output values of the graph."),(0,i.yg)("h3",{id:"postgraphid"},(0,i.yg)("inlineCode",{parentName:"h3"},"POST/:graphId")),(0,i.yg)("p",null,"This is only enabled if the ",(0,i.yg)("inlineCode",{parentName:"p"},"--allow-specifying-graph-id")," flag is used. This endpoint runs a specific graph in the project file."),(0,i.yg)("p",null,"The request body should contain the input values as described above."),(0,i.yg)("p",null,"Outputs a JSON object with the output values of the graph."),(0,i.yg)("h2",{id:"options"},"Options"),(0,i.yg)("h3",{id:"server-configuration"},"Server Configuration"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"--port <port>"),": The port to run the server on. Default is 3000."),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"--dev"),": Runs the server in development mode, which will reread the project file on each request. Useful for development.")),(0,i.yg)("h3",{id:"graph-selection"},"Graph Selection"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"--graph <graphNameOrId>"),": The name or ID of the graph to run. If not provided, the main graph will be run. If there is no main graph, an error will be returned."),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"--allow-specifying-graph-id"),": Allows specifying the graph ID in the URL path. This is disabled by default.")),(0,i.yg)("h3",{id:"openai-configuration"},"OpenAI Configuration"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"--openai-api-key"),": The OpenAI API key to use for the Chat node. Required if the project uses OpenAI functionality or otherwise requires an API key. If omitted, the environment variable ",(0,i.yg)("inlineCode",{parentName:"li"},"OPENAI_API_KEY")," will be used."),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"--openai-endpoint"),": The OpenAI API endpoint to use for the Chat node. Default is ",(0,i.yg)("inlineCode",{parentName:"li"},"https://api.openai.com/v1/chat/completions"),". If omitted, the environment variable ",(0,i.yg)("inlineCode",{parentName:"li"},"OPENAI_ENDPOINT")," will be used."),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"--openai-organization"),": The OpenAI organization ID to use. If omitted, the environment variable ",(0,i.yg)("inlineCode",{parentName:"li"},"OPENAI_ORGANIZATION")," will be used.")),(0,i.yg)("h3",{id:"monitoring"},"Monitoring"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"--expose-cost"),": Exposes the graph run cost as a property in the JSON response object. Disabled by default.")),(0,i.yg)("h2",{id:"examples"},"Examples"),(0,i.yg)("h3",{id:"running-a-simple-graph"},"Running a Simple Graph"),(0,i.yg)("p",null,"Request:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-bash"},'curl -X POST http://localhost:3000 -H "Content-Type: application/json" -d \'{\n  "name": "Alice",\n  "age": 30\n}\'\n')),(0,i.yg)("p",null,"Response:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "greeting": {\n    "type": "string",\n    "value": "Hello, Alice!"\n  },\n  "canVote": {\n    "type": "boolean",\n    "value": true\n  }\n}\n')),(0,i.yg)("h2",{id:"security-considerations"},"Security Considerations"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},"The server is intended for development and testing purposes"),(0,i.yg)("li",{parentName:"ul"},"No authentication is provided by the server, so it should not be exposed to the internet without additional security measures."),(0,i.yg)("li",{parentName:"ul"},"Consider running behind a reverse proxy if exposed to the internet, to add security features like SSL, rate limiting, and authentication."),(0,i.yg)("li",{parentName:"ul"},"Use environment variables for sensitive configuration like API keys")),(0,i.yg)("h2",{id:"streaming-mode"},"Streaming Mode"),(0,i.yg)("p",null,(0,i.yg)("inlineCode",{parentName:"p"},"rivet serve")," exposes two different streaming modes depending on the application you will be integrating with. In both cases, the server will\nstream events in the SSE (Server-Sent Events) format, which is a simple and efficient way to stream data from the server to the client."),(0,i.yg)("h3",{id:"rivet-events-streaming-mode"},"Rivet Events Streaming Mode"),(0,i.yg)("p",null,"By default, when ",(0,i.yg)("inlineCode",{parentName:"p"},"--stream")," is provided, the server will stream events in the Rivet Events format. This format is designed for application that\nunderstand the Rivet Events system, and can handle the events appropriately."),(0,i.yg)("p",null,"Here is an example of streamed responses in Rivet Events format:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre"},'event: nodeStart\ndata: {\n    "inputs": {\n        "prompt": {\n            "type": "string",\n            "value": "h4110"\n        }\n    },\n    "nodeId": "vzC9lcEyXZ2Q1-cCaG0v4",\n    "nodeTitle": "Chat",\n    "type": "nodeStart"\n}\n\nevent: partialOutput\ndata: {\n    "delta": "",\n    "nodeId": "vzC9lcEyXZ2Q1-cCaG0v4",\n    "nodeTitle": "Chat",\n    "type": "partialOutput"\n}\n\nevent: partialOutput\ndata: {\n    "delta": "It seems like you entered \\"h",\n    "nodeId": "vzC9lcEyXZ2Q1-cCaG0v4",\n    "nodeTitle": "Chat",\n    "type": "partialOutput"\n}\n\nevent: partialOutput\ndata: {\n    "delta": "4110.\\" Could",\n    "nodeId": "vzC9lcEyXZ2Q1-cCaG0v4",\n    "nodeTitle": "Chat",\n    "type": "partialOutput"\n}\n\nevent: partialOutput\ndata: {\n    "delta": " you please provide more context or clarify what you would like to know or",\n    "nodeId": "vzC9lcEyXZ2Q1-cCaG0v4",\n    "nodeTitle": "Chat",\n    "type": "partialOutput"\n}\n\nevent: partialOutput\ndata: {\n    "delta": " discuss regarding that term?",\n    "nodeId": "vzC9lcEyXZ2Q1-cCaG0v4",\n    "nodeTitle": "Chat",\n    "type": "partialOutput"\n}\n\nevent: nodeFinish\ndata: {\n    "nodeId": "vzC9lcEyXZ2Q1-cCaG0v4",\n    "nodeTitle": "Chat",\n    "outputs": {\n        "__hidden_token_count": {\n            "type": "number",\n            "value": 68\n        },\n        "all-messages": {\n            "type": "chat-message[]",\n            "value": [\n                {\n                    "message": "h4110",\n                    "type": "user"\n                },\n                {\n                    "message": "It seems like you entered \\"h4110.\\" Could you please provide more context or clarify what you would like to know or discuss regarding that term?",\n                    "type": "assistant"\n                }\n            ]\n        },\n        "cost": {\n            "type": "number",\n            "value": 2.475e-05\n        },\n        "duration": {\n            "type": "number",\n            "value": 846\n        },\n        "in-messages": {\n            "type": "chat-message[]",\n            "value": [\n                {\n                    "message": "h4110",\n                    "type": "user"\n                }\n            ]\n        },\n        "requestTokens": {\n            "type": "number",\n            "value": 10\n        },\n        "response": {\n            "type": "string",\n            "value": "It seems like you entered \\"h4110.\\" Could you please provide more context or clarify what you would like to know or discuss regarding that term?"\n        },\n        "responseTokens": {\n            "type": "number",\n            "value": 58\n        },\n        "usage": {\n            "type": "object",\n            "value": {\n                "completion_cost": 2.325e-05,\n                "completion_tokens": 31,\n                "completion_tokens_details": {\n                    "accepted_prediction_tokens": 0,\n                    "audio_tokens": 0,\n                    "reasoning_tokens": 0,\n                    "rejected_prediction_tokens": 0\n                },\n                "prompt_cost": 1.4999999999999998e-06,\n                "prompt_tokens": 10,\n                "prompt_tokens_details": {\n                    "audio_tokens": 0,\n                    "cached_tokens": 0\n                },\n                "total_cost": 2.475e-05,\n                "total_tokens": 41\n            }\n        }\n    },\n    "type": "nodeFinish"\n}\n')),(0,i.yg)("p",null,"You can see that the server is streaming events like ",(0,i.yg)("inlineCode",{parentName:"p"},"nodeStart"),", ",(0,i.yg)("inlineCode",{parentName:"p"},"partialOutputs"),", and ",(0,i.yg)("inlineCode",{parentName:"p"},"nodeFinish"),". The data for each of the events is\na JSON object with the relevant information for that event."),(0,i.yg)("h4",{id:"single-node-streaming-mode"},"Single-Node Streaming Mode"),(0,i.yg)("p",null,"If you set ",(0,i.yg)("inlineCode",{parentName:"p"},"--stream=NodeId")," or ",(0,i.yg)("inlineCode",{parentName:"p"},"--stream=NodeTitle"),", the server will only stream events for the specified node. This is useful if you are only interested in the\nevents for a specific node in the graph."),(0,i.yg)("h3",{id:"text-streaming-mode"},"Text Streaming Mode"),(0,i.yg)("p",null,"If you are integrating with a simple application that only likes having text responses, you can set ",(0,i.yg)("inlineCode",{parentName:"p"},"--stream-node=NodeId")," / ",(0,i.yg)("inlineCode",{parentName:"p"},"--stream-node=NodeTitle")," and ",(0,i.yg)("inlineCode",{parentName:"p"},"--stream")," together."),(0,i.yg)("p",null,"This will cause the streaming to look like the following:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre"},'data: ""\n\ndata: "It seems like you entered \\"h"\n\ndata: "4110,\\" which could refer"\n\ndata: " to a variety of things depending on the context."\n\ndata: " It could be a model number, a"\n\ndata: " code, or something else."\n\ndata: " Could you please provide more details or clarify what you"\n\ndata: " are referring to?"\n\ndata: " This will help me assist you better!"\n')),(0,i.yg)("p",null,"You can see that each ",(0,i.yg)("inlineCode",{parentName:"p"},"data")," event contains a delta of the response text from the node."),(0,i.yg)("p",null,"You should only specify Chat nodes for this mode, as other nodes may not have partial outputs that support this."))}g.isMDXComponent=!0}}]);