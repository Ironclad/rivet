"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[7112],{5591:(e,t,n)=>{n.d(t,{xA:()=>d,yg:()=>g});var r=n(8527);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function o(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},i=Object.keys(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var l=r.createContext({}),u=function(e){var t=r.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},d=function(e){var t=u(e.components);return r.createElement(l.Provider,{value:t},e.children)},c="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},p=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,i=e.originalType,l=e.parentName,d=o(e,["components","mdxType","originalType","parentName"]),c=u(n),p=a,g=c["".concat(l,".").concat(p)]||c[p]||m[p]||i;return n?r.createElement(g,s(s({ref:t},d),{},{components:n})):r.createElement(g,s({ref:t},d))}));function g(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=n.length,s=new Array(i);s[0]=p;var o={};for(var l in t)hasOwnProperty.call(t,l)&&(o[l]=t[l]);o.originalType=e,o[c]="string"==typeof e?e:a,s[1]=o;for(var u=2;u<i;u++)s[u]=n[u];return r.createElement.apply(null,s)}return r.createElement.apply(null,n)}p.displayName="MDXCreateElement"},9605:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>m,frontMatter:()=>i,metadata:()=>o,toc:()=>u});var r=n(4465),a=(n(8527),n(5591));const i={sidebar_label:"AssemblyAI"},s="AssemblyAI Plugin",o={unversionedId:"user-guide/plugins/built-in/assemblyai",id:"user-guide/plugins/built-in/assemblyai",title:"AssemblyAI Plugin",description:"Nodes",source:"@site/docs/user-guide/plugins/built-in/assemblyai.md",sourceDirName:"user-guide/plugins/built-in",slug:"/user-guide/plugins/built-in/assemblyai",permalink:"/docs/user-guide/plugins/built-in/assemblyai",draft:!1,editUrl:"https://github.com/ironclad/rivet/tree/main/packages/docs/docs/user-guide/plugins/built-in/assemblyai.md",tags:[],version:"current",frontMatter:{sidebar_label:"AssemblyAI"},sidebar:"userGuide",previous:{title:"Anthropic",permalink:"/docs/user-guide/plugins/built-in/anthropic"},next:{title:"Autoevals",permalink:"/docs/user-guide/plugins/built-in/autoevals"}},l={},u=[{value:"Nodes",id:"nodes",level:2},{value:"Transcribe Audio Node",id:"transcribe-audio-node",level:3},{value:"LeMUR Nodes",id:"lemur-nodes",level:3},{value:"LeMUR Summary Node",id:"lemur-summary-node",level:4},{value:"LeMUR Q&amp;A Node",id:"lemur-qa-node",level:4},{value:"LeMUR Custom Task Node",id:"lemur-custom-task-node",level:4},{value:"LeMUR Action Items Node",id:"lemur-action-items-node",level:4}],d={toc:u},c="wrapper";function m(e){let{components:t,...i}=e;return(0,a.yg)(c,(0,r.A)({},d,i,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("h1",{id:"assemblyai-plugin"},"AssemblyAI Plugin"),(0,a.yg)("h2",{id:"nodes"},"Nodes"),(0,a.yg)("h3",{id:"transcribe-audio-node"},"Transcribe Audio Node"),(0,a.yg)("p",null,"The Transcribe Audio node transcribes audio using the ",(0,a.yg)("a",{parentName:"p",href:"https://www.assemblyai.com/?utm_source=rivet"},"AssemblyAI")," API. It will return a transcript of the given audio source."),(0,a.yg)("p",null,(0,a.yg)("img",{alt:"Transcribe Audio Node",src:n(9123).A,width:"716",height:"500"})),(0,a.yg)("h3",{id:"lemur-nodes"},"LeMUR Nodes"),(0,a.yg)("p",null,"AssemblyAI's LeMUR (Leveraging Large Language Models to Understand Recognized Speech) is a framework to process audio files with an LLM.\nThe AssemblyAI plugin has a dedicated node for each LeMUR endpoint.\nEach node accepts Transcript IDs or Input Text as input which you can get from the Transcribe Audio Node. Additional parameters are available as inputs and as node configuration. For more information what these parameters do, ",(0,a.yg)("a",{parentName:"p",href:"https://www.assemblyai.com/docs/api-reference/lemur?utm_source=lemur"},"check out the LeMUR API reference"),"."),(0,a.yg)("h4",{id:"lemur-summary-node"},"LeMUR Summary Node"),(0,a.yg)("p",null,"The LeMUR Summary node uses LeMUR to summarize a given transcript."),(0,a.yg)("p",null,(0,a.yg)("img",{alt:"LeMUR Summary Node",src:n(457).A,width:"836",height:"376"})),(0,a.yg)("h4",{id:"lemur-qa-node"},"LeMUR Q&A Node"),(0,a.yg)("p",null,"Given a transcript and questions, LeMUR can generate answers."),(0,a.yg)("p",null,(0,a.yg)("img",{alt:"LeMUR Question &amp; Answer Node",src:n(5711).A,width:"620",height:"422"})),(0,a.yg)("h4",{id:"lemur-custom-task-node"},"LeMUR Custom Task Node"),(0,a.yg)("p",null,"Given a transcript and prompt, LeMUR can will generate a response from the prompt and transcript."),(0,a.yg)("p",null,(0,a.yg)("img",{alt:"LeMUR Custom Task Node",src:n(8874).A,width:"794",height:"420"})),(0,a.yg)("h4",{id:"lemur-action-items-node"},"LeMUR Action Items Node"),(0,a.yg)("p",null,"Given a transcript of a meeting, the LeMUR Action Items node will return a list of action items from the meeting."),(0,a.yg)("p",null,(0,a.yg)("img",{alt:"LeMUR Action Items Node",src:n(1812).A,width:"910",height:"402"})))}m.isMDXComponent=!0},1812:(e,t,n)=>{n.d(t,{A:()=>r});const r=n.p+"assets/images/lemur-action-items-node-f674f7f9d98ed1640f04d7a1a61955b3.png"},5711:(e,t,n)=>{n.d(t,{A:()=>r});const r=n.p+"assets/images/lemur-qna-node-264f1047fe45c5b0eab0525aad7cad07.png"},457:(e,t,n)=>{n.d(t,{A:()=>r});const r=n.p+"assets/images/lemur-summary-node-a8e975ee1060597e2edd5d28b0bd4f3e.png"},8874:(e,t,n)=>{n.d(t,{A:()=>r});const r=n.p+"assets/images/lemur-task-node-f3d9e93525cd35a2580e6b684eacb765.png"},9123:(e,t,n)=>{n.d(t,{A:()=>r});const r=n.p+"assets/images/transcribe-audio-node-4b51aaab1077ea2a7a459dc800f2e754.png"}}]);